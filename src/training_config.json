{
  "model": {
    "hidden_size": 2048,
    "attention_heads": 8,
    "lstm_layers": 3,
    "lstm_hidden_size": 1024
  },
  "training": {
    "batch_size": 256,
    "memory_buffer_size": 500000,
    "episodes": 3000,
    "learning_rate": 0.0001
  },
  "optimization": "high"
}